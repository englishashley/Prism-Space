{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Global Iteration 1\n",
      "Satellite 3 training & transmitting (T_C=0.0910 sec)\n",
      "Satellite 9 training & transmitting (T_C=0.0155 sec)\n",
      "Satellite 13 training & transmitting (T_C=0.1085 sec)\n",
      "Satellite 19 training & transmitting (T_C=0.0226 sec)\n",
      "Satellite 28 training & transmitting (T_C=0.0148 sec)\n",
      "Satellite 29 training & transmitting (T_C=0.0183 sec)\n",
      "Satellite 32 training & transmitting (T_C=0.0280 sec)\n",
      "Satellite 33 training & transmitting (T_C=0.0811 sec)\n",
      "Satellite 34 training & transmitting (T_C=0.0327 sec)\n",
      "Satellite 37 training & transmitting (T_C=0.0164 sec)\n",
      "Satellite 38 training & transmitting (T_C=0.0223 sec)\n",
      "Global Model Updated!\n",
      "\n",
      " Global Iteration 2\n",
      "Satellite 1 training & transmitting (T_C=0.0373 sec)\n",
      "Satellite 2 training & transmitting (T_C=0.0163 sec)\n",
      "Satellite 8 training & transmitting (T_C=0.0445 sec)\n",
      "Satellite 16 training & transmitting (T_C=0.0245 sec)\n",
      "Satellite 23 training & transmitting (T_C=0.2611 sec)\n",
      "Satellite 24 training & transmitting (T_C=0.0141 sec)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''\n",
    "This Python code simulates a Federated Learning (FL) framework in a satellite constellation, \n",
    "incorporating scheduling logic and inter-satellite communication constraints. \n",
    "It is aligned with the FL approach discussed in the paper and Prism Space's goals of optimizing \n",
    "space-based AI compute infrastructure.\n",
    "\n",
    "### Modifications:\n",
    "- **Restored Loss Graph** (Tracks loss over global iterations)\n",
    "- **Fixed Power Calculation** (Idle power applied correctly per epoch)\n",
    "- **Simplified Power Graph** (Shows power per satellite over training)\n",
    "- **Better Histogram Representation** (Bins increased for clarity)\n",
    "- **Debugging Prints** (Optional, useful for inspecting power values)\n",
    "'''\n",
    "\n",
    "# --- Simulation Parameters ---\n",
    "num_sats = 40  # Total satellites\n",
    "epochs = 5  # Local training epochs\n",
    "global_iterations = 5  # Number of global updates\n",
    "visibility_probability = 0.7  # 70% chance a satellite is visible\n",
    "samples_per_sat = torch.randint(500, 5000, (num_sats,))  # Dataset size per satellite\n",
    "total_samples = torch.sum(samples_per_sat).item()  # Total dataset size\n",
    "\n",
    "# Generate Visibility Matrix (1 = Visible, 0 = Not Visible)\n",
    "visibility_matrix = np.random.choice([0, 1], size=(num_sats, global_iterations), p=[visibility_probability, 1 - visibility_probability])\n",
    "\n",
    "# --- SATELLITE SPECIFICATIONS ---\n",
    "power_train = 50  # Watts (Estimated Power for Local Model Training)\n",
    "power_transmit = 10  # Watts (Estimated Power for Transmission)\n",
    "power_idle = 5  # Watts (Baseline Idle Power Consumption)\n",
    "update_size = 1e6  # 1 MB update size\n",
    "\n",
    "# Transmission Parameters\n",
    "c = 3e8  # Speed of light (m/s)\n",
    "transmission_rates = np.random.uniform(1e6, 1e8, size=num_sats)  # 1 Mbps - 100 Mbps\n",
    "distances = np.random.uniform(500e3, 2000e3, size=num_sats)  # 500 km - 2000 km\n",
    "\n",
    "# Function to Compute Transmission Time\n",
    "def compute_transmission_time(data_size, rate, distance):\n",
    "    return (data_size / rate) + (distance / c)\n",
    "\n",
    "# --- Create Synthetic Dataset ---\n",
    "image_size = (3, 32, 32)\n",
    "X_data = torch.randn(total_samples, *image_size, dtype=torch.float32)  # Ensure float32\n",
    "Y_data = torch.randint(0, 10, (total_samples,))  # Class labels\n",
    "\n",
    "# Split data into per-satellite datasets\n",
    "satellite_datasets = []\n",
    "start_idx = 0\n",
    "for sat_idx in range(num_sats):\n",
    "    end_idx = start_idx + samples_per_sat[sat_idx].item()\n",
    "    dataset = TensorDataset(X_data[start_idx:end_idx], Y_data[start_idx:end_idx])\n",
    "    satellite_datasets.append(dataset)\n",
    "    start_idx = end_idx\n",
    "\n",
    "# --- Define the FL Model ---\n",
    "class SatelliteCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SatelliteCNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 8 * 8, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# --- Train Each Satellite & Compute Power Consumption ---\n",
    "global_losses = []\n",
    "power_usage = np.zeros(num_sats)  # Store total power usage per satellite\n",
    "\n",
    "for global_iter in range(global_iterations):\n",
    "    print(f\"\\n Global Iteration {global_iter + 1}\")\n",
    "\n",
    "    visibility = visibility_matrix[:, global_iter]\n",
    "    local_models = [None] * num_sats  # Initialize list with None values\n",
    "    local_losses = [0.0] * num_sats  # Ensure same size as num_sats\n",
    "\n",
    "    for i in range(num_sats):\n",
    "        if visibility[i] == 1:\n",
    "            # Compute transmission time\n",
    "            T_C = compute_transmission_time(update_size, transmission_rates[i], distances[i])\n",
    "\n",
    "            if T_C < 0.5:\n",
    "                print(f\"Satellite {i+1} training & transmitting (T_C={T_C:.4f} sec)\")\n",
    "\n",
    "                train_loader = DataLoader(satellite_datasets[i], batch_size=32, shuffle=True)\n",
    "\n",
    "                model = SatelliteCNN()\n",
    "                optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "                criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "                # Training Loop\n",
    "                model.train()\n",
    "                for epoch in range(epochs):\n",
    "                    for batch in train_loader:\n",
    "                        x, y = batch\n",
    "                        optimizer.zero_grad()\n",
    "                        outputs = model(x)\n",
    "                        loss = criterion(outputs, y)\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Compute Power Consumption\n",
    "                power_train_usage = power_train * epochs  # Training power\n",
    "                power_transmit_usage = power_transmit * T_C  # Transmission power\n",
    "                power_idle_usage = power_idle * epochs  # Idle power over training period\n",
    "\n",
    "                power_usage[i] += power_train_usage + power_transmit_usage + power_idle_usage  # Total Power\n",
    "\n",
    "                local_models[i] = model.state_dict()\n",
    "                local_losses[i] = loss.item()\n",
    "\n",
    "    # --- Global Model Aggregation ---\n",
    "    global_model = SatelliteCNN()\n",
    "    for param in global_model.state_dict().keys():\n",
    "        weighted_sum = torch.zeros_like(global_model.state_dict()[param])\n",
    "        total_weight = 0\n",
    "\n",
    "        for i in range(num_sats):\n",
    "            if local_models[i] is not None:\n",
    "                weighted_sum += (samples_per_sat[i].item() / total_samples) * local_models[i][param]\n",
    "                total_weight += samples_per_sat[i].item()\n",
    "\n",
    "        if total_weight > 0:\n",
    "            global_model.state_dict()[param].copy_(weighted_sum)\n",
    "\n",
    "    global_loss = sum(local_losses) / len(local_losses)\n",
    "    global_losses.append(global_loss)\n",
    "    print(\"Global Model Updated!\")\n",
    "\n",
    "# --- Visualization Section ---\n",
    "\n",
    "# **1. Loss Reduction Over Iterations**\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(global_iterations), global_losses, marker='o', linestyle='-')\n",
    "plt.xlabel(\"Global FL Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Federated Learning Loss Reduction Over Iterations\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# **2. Power Consumption Per Satellite**\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(num_sats), power_usage, color=\"blue\", alpha=0.7)\n",
    "plt.xlabel(\"Satellite Index\")\n",
    "plt.ylabel(\"Total Power Consumption (Joules)\")\n",
    "plt.title(\"Total Power Consumption Per Satellite\")\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "# --- Check Transmission Delays ---\n",
    "print(\"\\n Checking Transmission Times for Each Satellite:\")\n",
    "for i in range(num_sats):\n",
    "    T_C = compute_transmission_time(update_size, transmission_rates[i], distances[i])\n",
    "    print(f\"Satellite {i+1}: Transmission Time = {T_C:.4f} sec\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
